<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>STRUC2VEC（图结构→向量）论文方法解读 | Jackie Anxis</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="STRUC2VEC原文：struc2vec: Learning Node Representations from Structural Identity 捕捉节点在网络中的结构信息，将它表达成一个高维向量，需要考虑以下两个相关的性质：  不同节点的表达之间的距离（也就是高维向量之间的距离）应该跟他们的结构之间的相似度高度相关。 节点的这种结构表达，不应该依赖于节点或者边的属性以及它们的标签。节点">
<meta name="keywords" content="机器学习,图数据挖掘">
<meta property="og:type" content="article">
<meta property="og:title" content="STRUC2VEC（图结构→向量）论文方法解读">
<meta property="og:url" content="http://jackieanxis.github.io/2018/01/17/struc2vec: Learning Node Representations from Structural Identity/index.html">
<meta property="og:site_name" content="Jackie Anxis">
<meta property="og:description" content="STRUC2VEC原文：struc2vec: Learning Node Representations from Structural Identity 捕捉节点在网络中的结构信息，将它表达成一个高维向量，需要考虑以下两个相关的性质：  不同节点的表达之间的距离（也就是高维向量之间的距离）应该跟他们的结构之间的相似度高度相关。 节点的这种结构表达，不应该依赖于节点或者边的属性以及它们的标签。节点">
<meta property="og:locale" content="Chinese">
<meta property="og:updated_time" content="2018-06-05T06:08:30.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="STRUC2VEC（图结构→向量）论文方法解读">
<meta name="twitter:description" content="STRUC2VEC原文：struc2vec: Learning Node Representations from Structural Identity 捕捉节点在网络中的结构信息，将它表达成一个高维向量，需要考虑以下两个相关的性质：  不同节点的表达之间的距离（也就是高维向量之间的距离）应该跟他们的结构之间的相似度高度相关。 节点的这种结构表达，不应该依赖于节点或者边的属性以及它们的标签。节点">
  
  
    <link rel="icon" href="http://o6vut8vrh.bkt.clouddn.com/avatar.png">
  
  <link rel="stylesheet" href="/papers/css/typing.css">
  <link rel="stylesheet" href="/papers/css/donate.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>

  
    
      <body>
    
  
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container" class="container">
        <article id="post-struc2vec: Learning Node Representations from Structural Identity" class="article article-type-post" itemscope itemprop="blogPost">
  <header id="header" class="header">
    <div class="mobile-nav">
      <h1 class="nickname">Jackie Anxis</h1>
      <a id="menu">
        &#9776; Menu
      </a>
    </div>
    
        <nav id="main-nav" class="main-nav nav-left">
    
    
      <a class="main-nav-link" href="http://jackieanxis.github.io">Home</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/frontend">FrontEnd</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/cs229">MLcs229</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/papers">PaperReading</a>
    
      <a class="main-nav-link" href="https://github.com/JackieAnxis">Github</a>
    
      <a class="main-nav-link" href="http://jackieanxis.github.io/others">Others</a>
    
      <a class="main-nav-link" href="/papers/about">About</a>
    
  </nav>
</header>

  <hr/>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      STRUC2VEC（图结构→向量）论文方法解读
    </h1>
  

      </header>
    
    <div class="article-entry typo" itemprop="articleBody">
      
        <h2 id="STRUC2VEC"><a href="#STRUC2VEC" class="headerlink" title="STRUC2VEC"></a>STRUC2VEC</h2><p>原文：struc2vec: Learning Node Representations from Structural Identity</p>
<p>捕捉节点在网络中的结构信息，将它表达成一个高维向量，需要考虑以下两个相关的性质：</p>
<ol>
<li>不同节点的表达之间的距离（也就是高维向量之间的距离）应该跟他们的结构之间的相似度高度相关。</li>
<li>节点的这种结构表达，不应该依赖于节点或者边的属性以及它们的标签。节点的结构信息应该跟他们在网络中的位置不相关。</li>
</ol>
<p><strong>STRUC2VEC</strong>的基本步骤：</p>
<ol>
<li><p>在不同的邻域大小下，比较图中的每个节点之间的结构相似度。</p>
<p>产生一个结构相似度度量的多层模型（hierarchy）。</p>
</li>
<li><p>构造一个带权的多层图，网络中所有的节点都会出现在每一层，每一层都会和度量结构相似度的多层模型（hierarchy）的每一级相对应。然后带权多层图的边的权重和该边相关的节点对之间的距离成反比。</p>
</li>
<li><p>使用上述的多层图生成每个节点的上下文。用带偏的random walk来生成多层图的节点序列。</p>
</li>
<li><p>使用某种技术，通过节点序列给出的上下文来学习潜在表达</p>
</li>
</ol>
<h4 id="第一步：度量结构相似度"><a href="#第一步：度量结构相似度" class="headerlink" title="第一步：度量结构相似度"></a>第一步：度量结构相似度</h4><ul>
<li><p>$R_k(u)$表示了节点$u$的$k$级邻域。</p>
</li>
<li><p>$s(S)$则表示节点的集合$S \subset V$的度数序列。</p>
</li>
<li><p>$g(D_1,D_2)$度量了两个度数序列$D1,D2$之间的距离</p>
</li>
<li><p>$f_k(u,v)$表示了$u,v$两节点之间，$k$级邻域（距离小于等于$k$的节点和所有它们之间的边）的结构距离。</p>
<p>$f_k(u,v) = f_{k-1}(u,v) + g(s(R_k(u)), s(R_k(v)))$</p>
<p>$f_{-1} = 0$</p>
<p>上述定义表达的是一个递归的过程，把问题转换成了如何定义两个节点集合之间的距离，也就是$g(\cdot)$该如何计算。</p>
</li>
<li><p>文章使用了Dynamic Time Warping(DTW)来度量两个度数序列之间的距离。</p>
<p>序列A和B，其中，$a \in A$，$b \in B$，那么$a, b$之间的距离定义为：$d(a, b) = \frac{max(a, b)}{min(a, b)} - 1$，当$a=b$时，他们的距离也就是0。然后两个序列之间的距离，也就是所有$a,b$组合之间的距离和。</p>
<p>其他方案也可以用在该框架下，感觉这里的时间复杂度相对较高，可以有替换的方案。VIGOR论文中提到的方法？</p>
</li>
</ul>
<h4 id="第二步：构造上下文图（context-graph）"><a href="#第二步：构造上下文图（context-graph）" class="headerlink" title="第二步：构造上下文图（context graph）"></a>第二步：构造上下文图（context graph）</h4><ul>
<li><p>构造一个带权的多层图$M$。层数由$0到k^<em>$，其中$k^</em>$表示的是图的直径，也就是原始图$G=(V,E)$中节点之间的最远距离。</p>
</li>
<li><p>第$k$层图表达的是节点之间$k$级邻域的相似度度量。</p>
</li>
<li><p>故而$M$的每一层都是一个完全图，都会有$n=|V|$个节点，边的数量是$n(n-1)$，边的权重的定义：</p>
<p>$$w_k(u,v) = e^{-f_k(u,v)},k=0,…,k^*$$</p>
<p>当然，只有$f_k$定义了，边才能被定义。</p>
</li>
<li><p>因为$f_k(u,v)$最小是0，那么边的权重$w_k(u,v)$的取值范围是$(0,1]$，当等于1时，代表两个节点结构相同。</p>
</li>
<li><p>不同层级之间，通过有向边连接，在$k$层的每个节点都会跟$k-1$层和$k+1$层的相同节点用有向边连接，边的权重定义：</p>
<p>$$w(u_k,u_{k+1})=log(\Gamma_k(u)+e), k=0,…,k^∗−1$$</p>
<p>$$w(u_k,u_{k-1})=1,k=1,…,k^∗$$</p>
<ul>
<li>其中$\Gamma_k(u)$代表了指向节点$u$的权重大于$k$层图平均权重的边的数量：$\Gamma_k(u)=\sum_{v \in V} \mathbb{1}(w_k(u,v) &gt; \overline{w_k})$，也就是度量了该节点$u$和第$k$层其他节点之间的相似度。</li>
<li>而$\overline{w_k} = \sum_{(u,v)\in  \begin{pmatrix} V \ 2 \ \end{pmatrix} }w_k(u,v)/\begin{pmatrix} n \ 2 \end{pmatrix}$</li>
</ul>
</li>
</ul>
<h4 id="第三步：生成节点的上下文"><a href="#第三步：生成节点的上下文" class="headerlink" title="第三步：生成节点的上下文"></a>第三步：生成节点的上下文</h4><p>利用$M$生成节点的上下文的过程：带偏的随机游走（biased random walk）。</p>
<ul>
<li><p>首先需要决定，随机游走的这一步，是留在当前层还是换层</p>
</li>
<li><p>有一定概率$q$，留在当前层，假设留在当前层，那么从节点$u$走到$v$的概率（权重越大，概率越高，也就是更容易走到相似节点上）：</p>
<p>$$p_k(u,v) = \frac{e^{-f_k(u,v)}}{Z_k(u)}$$，$$Z_k(u)=\sum_{v \in V, v ≠ u} e^{-f_k*(u,v)}$$</p>
</li>
<li><p>假设在另一半概率上$1-q$，换层，换到$k+1$的概率定义：</p>
<p>$$p_k(u_k, u_{k+1}) = \frac{w(u_k, u_{k+1})}{(u_k, u_{k+1})+(u_k, u_{k-1})}$$</p>
<p>而换到$k-1$层的概率：</p>
<p>$$p_k(u_k, u_{k-1}) = 1 - p_k(u_k, u_{k+1})$$</p>
</li>
<li><p>当节点走到$k+1$层时，产生的context可能只是前$k$层产生的context的一个子集，所以这种情况下，并不没有贡献</p>
</li>
<li><p>每次随机游走从第0层开始，游走步数都是一个固定的，较小的值，然后随机游走会在同一个节点上重复多次，产生多个独立的游走</p>
</li>
</ul>
<h4 id="第四步：学习语言模型"><a href="#第四步：学习语言模型" class="headerlink" title="第四步：学习语言模型"></a>第四步：学习语言模型</h4><p>通过word embedding的方法，对第三步生成的随机游走结果，生成高维向量。</p>
<p>文章使用了<strong>Skip-Gram</strong>[^1]。</p>
<p>[^1]: Mikolov, Tomas, et al. “Efficient estimation of word representations in vector space.” <em>arXiv preprint arXiv:1301.3781</em> (2013).</p>

      
    </div>
    <footer class="article-footer">
      <ul class="article-meta">
        <li>
          <span class="label">Published Date:</span>
          <a href="/papers/2018/01/17/struc2vec: Learning Node Representations from Structural Identity/" class="article-date">
  <time datetime="2018-01-17T09:29:00.000Z" itemprop="datePublished">2018-01-17</time>
</a>

        </li>
        
          <li>
            <span class="label">Categoría:</span>
            
  <div class="article-category">
    <a class="article-category-link" href="/papers/categories/图数据挖掘/">图数据挖掘</a>
  </div>


          </li>
        
        
          <li>
            <span class="label">Tag:</span>
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/papers/tags/图数据挖掘/">图数据挖掘</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/papers/tags/机器学习/">机器学习</a></li></ul>


          </li>
        
        <hr/>
      </ul>
    </footer>
  </div>
  
    
<nav id="article-nav" class="article-nav">
  
    <a href="/papers/2018/04/26/iSphere: Focus+Context Sphere Visualization for Interactive Large Graph Exploration/" id="article-nav-newer" class="article-nav-link-wrap newer">
      <strong class="article-nav-caption">Nuevo</strong>
      <div class="article-nav-title">
        
          iSphere-交互式探索大规模图的焦点+上下文球体可视化技术
        
      </div>
    </a>
  
  
    <a href="/papers/2017/10/03/A Survey on Graph Visualization/" id="article-nav-older" class="article-nav-link-wrap older">
      <strong class="article-nav-caption">Viejo</strong>
      <div class="article-nav-title">A Survey on Graph Visualization</div>
    </a>
  
</nav>


  
</article>








      </div>
      
    <footer id="footer" class="post-footer footer">
      
      <hr/>
      <div id="footerContent" class="footer-content">
        <p>nothing</p>


      </div>
    </footer>

      





<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.10/clipboard.min.js"></script>


  <link rel="stylesheet" href="/papers/fancybox/jquery.fancybox.css">
  <script src="/papers/fancybox/jquery.fancybox.pack.js"></script>


<script src="/papers/js/typing.js"></script>
<!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->







    </div>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
